{
    "version": "2.0.0",
    "tasks": [
        {
            "label": "LiveBench: Run Benchmark Group (Local)",
            "type": "shell",
            "command": "${workspaceFolder}/.venv/bin/python3",
            "args": [
                "run_and_show_results.py",
                "--model",
                "${input:localModel}",
                "--benchmark",
                "${input:mainCategory}",
                "--parallel",
                "4"
            ],
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": true,
                "panel": "shared"
            },
            "group": {
                "kind": "build",
                "isDefault": true
            }
        },
        {
            "label": "LiveBench: Run Specific Benchmark (Local)",
            "type": "shell",
            "command": "${workspaceFolder}/.venv/bin/python3",
            "args": [
                "run_and_show_results.py",
                "--model",
                "${input:localModel}",
                "--benchmark",
                "${input:specificTest}",
                "--parallel",
                "4"
            ],
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": true,
                "panel": "shared"
            }
        },
        {
            "label": "LiveBench: Run Benchmark Group (API)",
            "type": "shell",
            "command": "${workspaceFolder}/.venv/bin/python3",
            "args": [
                "run_and_show_results.py",
                "--model",
                "${input:apiModel}",
                "--benchmark",
                "${input:mainCategory}",
                "--parallel",
                "15",
                "--api"
            ],
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": true,
                "panel": "shared"
            }
        },
        {
            "label": "LiveBench: Run Specific Benchmark (API)",
            "type": "shell",
            "command": "${workspaceFolder}/.venv/bin/python3",
            "args": [
                "run_and_show_results.py",
                "--model",
                "${input:apiModel}",
                "--benchmark",
                "${input:specificTest}",
                "--parallel",
                "4",
                "--api"
            ],
            "problemMatcher": [],
            "presentation": {
                "echo": true,
                "reveal": "always",
                "focus": true,
                "panel": "shared"
            }
        }
    ],
    "inputs": [
        {
            "id": "localModel",
            "type": "pickString",
            "description": "Select local Ollama model",
            "options": [
                "qwen2.5:3b",
                "llama3:latest",
                "llama2",
                "gpt-oss:latest"
            ],
            "default": "qwen2.5:3b"
        },
        {
            "id": "apiModel",
            "type": "pickString",
            "description": "Select API model (OpenAI or Gemini)",
            "options": [
                "gpt-5-mini",
                "gpt-5",
                "gpt-5-nano",
                "gemini-2.5-flash-06-05-nothinking",
                "gemini-2.5-flash-06-05-highthinking"
            ],
            "default": "gpt-4o-mini"
        },
        {
            "id": "benchmark",
            "type": "promptString",
            "description": "Enter benchmark name (e.g., custom_tests, live_bench/reasoning/web_of_lies_v2)",
            "default": "custom_tests"
        },
        {
            "id": "mainCategory",
            "type": "pickString",
            "description": "Select main benchmark category",
            "options": [
                "custom_tests",
                "custom_tests/basic_math",
                "custom_tests/translation",
                "live_bench/reasoning",
                "live_bench/math",
                "live_bench/coding",
                "live_bench/data_analysis",
                "live_bench/instruction_following",
                "live_bench/language"
            ],
            "default": "custom_tests"
        },
        {
            "id": "specificTest",
            "type": "pickString",
            "description": "Select specific test to run",
            "options": [
                "custom_tests/basic_math",
                "custom_tests/translation",
                "live_bench/reasoning/web_of_lies_v2",
                "live_bench/reasoning/zebra_puzzle",
                "live_bench/reasoning/spatial",
                "live_bench/math/AMPS_Hard",
                "live_bench/math/math_comp",
                "live_bench/math/olympiad",
                "live_bench/coding/coding_completion",
                "live_bench/coding/LCB_generation",
                "live_bench/data_analysis/cta",
                "live_bench/data_analysis/tablejoin",
                "live_bench/data_analysis/tablereformat",
                "live_bench/instruction_following/paraphrase",
                "live_bench/instruction_following/simplify",
                "live_bench/instruction_following/story_generation",
                "live_bench/instruction_following/summarize",
                "live_bench/language/typos",
                "live_bench/language/connections",
                "live_bench/language/plot_unscrambling"
            ],
            "default": "custom_tests/basic_math"
        }
    ]
}
